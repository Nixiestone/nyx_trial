"""
Random Forest Model - Model 1
Author: BLESSING OMOREGIE
GitHub: Nixiestone
Repository: nyx_trial

DO NOT EDIT THIS FILE
Random Forest Classifier for price direction prediction.
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
from pathlib import Path
from typing import Optional, Tuple

from ..utils.logger import get_logger


class RandomForestModel:
    """
    Random Forest model for predicting price direction.
    Predicts: -1 (sell), 0 (neutral), 1 (buy)
    """
    
    def __init__(self, config):
        """
        Initialize Random Forest model.
        
        Args:
            config: Settings object
        """
        self.config = config
        self.logger = get_logger(__name__, config.LOG_LEVEL, config.LOG_FILE_PATH)
        
        # Initialize model
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        
        self.scaler = StandardScaler()
        self.is_trained = False
        self.feature_names = []
    
    def prepare_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Prepare technical indicator features from OHLCV data.
        
        Args:
            df: DataFrame with OHLCV data
            
        Returns:
            DataFrame with features
        """
        features = pd.DataFrame(index=df.index)
        
        # Price-based features
        features['returns'] = df['close'].pct_change()
        features['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        features['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        features['close_open_ratio'] = (df['close'] - df['open']) / df['open']
        
        # Moving averages
        for period in [5, 10, 20, 50, 100, 200]:
            features[f'sma_{period}'] = df['close'].rolling(period).mean()
            features[f'ema_{period}'] = df['close'].ewm(span=period).mean()
            features[f'price_to_sma_{period}'] = df['close'] / features[f'sma_{period}']
            features[f'price_to_ema_{period}'] = df['close'] / features[f'ema_{period}']
        
        # Volatility features
        features['volatility_10'] = df['close'].rolling(10).std()
        features['volatility_20'] = df['close'].rolling(20).std()
        features['volatility_50'] = df['close'].rolling(50).std()
        features['atr_14'] = self._calculate_atr(df, 14)
        
        # Volume features
        features['volume'] = df['volume']
        features['volume_ma_10'] = df['volume'].rolling(10).mean()
        features['volume_ma_20'] = df['volume'].rolling(20).mean()
        features['volume_ratio_10'] = df['volume'] / features['volume_ma_10']
        features['volume_ratio_20'] = df['volume'] / features['volume_ma_20']
        
        # Momentum indicators
        features['rsi_14'] = self._calculate_rsi(df['close'], 14)
        features['rsi_21'] = self._calculate_rsi(df['close'], 21)
        features['mom_10'] = df['close'].diff(10)
        features['mom_20'] = df['close'].diff(20)
        features['roc_10'] = df['close'].pct_change(10)
        features['roc_20'] = df['close'].pct_change(20)
        
        # MACD
        macd, signal, hist = self._calculate_macd(df['close'])
        features['macd'] = macd
        features['macd_signal'] = signal
        features['macd_hist'] = hist
        
        # Bollinger Bands
        bb_upper, bb_middle, bb_lower = self._calculate_bollinger_bands(df['close'], 20)
        features['bb_upper'] = bb_upper
        features['bb_middle'] = bb_middle
        features['bb_lower'] = bb_lower
        features['bb_width'] = (bb_upper - bb_lower) / bb_middle
        features['bb_position'] = (df['close'] - bb_lower) / (bb_upper - bb_lower)
        
        # Stochastic Oscillator
        stoch_k, stoch_d = self._calculate_stochastic(df, 14)
        features['stoch_k'] = stoch_k
        features['stoch_d'] = stoch_d
        
        # Price patterns
        features['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        features['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        features['inside_bar'] = ((df['high'] < df['high'].shift(1)) & 
                                   (df['low'] > df['low'].shift(1))).astype(int)
        features['outside_bar'] = ((df['high'] > df['high'].shift(1)) & 
                                    (df['low'] < df['low'].shift(1))).astype(int)
        
        # Trend strength
        features['adx_14'] = self._calculate_adx(df, 14)
        
        # Drop NaN values
        features = features.fillna(method='bfill').fillna(0)
        
        self.feature_names = features.columns.tolist()
        
        return features
    
    def train(self, df: pd.DataFrame, labels: np.ndarray) -> dict:
        """
        Train the Random Forest model.
        
        Args:
            df: DataFrame with OHLCV data
            labels: Array of labels (-1, 0, 1)
            
        Returns:
            Dictionary with training metrics
        """
        try:
            self.logger.info("Training Random Forest model...")
            
            # Prepare features
            X = self.prepare_features(df)
            
            # Remove rows with NaN in labels
            valid_idx = ~np.isnan(labels)
            X = X[valid_idx]
            y = labels[valid_idx]
            
            # Scale features
            X_scaled = self.scaler.fit_transform(X)
            
            # Train model
            self.model.fit(X_scaled, y)
            
            # Calculate training accuracy
            train_score = self.model.score(X_scaled, y)
            
            self.is_trained = True
            
            self.logger.info(f"Random Forest trained. Accuracy: {train_score:.4f}")
            
            # Feature importance
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            self.logger.debug(f"Top 10 features:\n{feature_importance.head(10)}")
            
            return {
                'model': 'random_forest',
                'accuracy': train_score,
                'n_samples': len(y),
                'n_features': X.shape[1],
                'top_features': feature_importance.head(10).to_dict('records')
            }
            
        except Exception as e:
            self.logger.exception(f"Error training Random Forest: {e}")
            return {'model': 'random_forest', 'error': str(e)}
    
    def predict(self, df: pd.DataFrame) -> Tuple[int, float]:
        """
        Predict price direction.
        
        Args:
            df: DataFrame with OHLCV data
            
        Returns:
            Tuple of (prediction, confidence)
        """
        if not self.is_trained:
            self.logger.warning("Model not trained, returning neutral prediction")
            return 0, 0.33
        
        try:
            # Prepare features
            X = self.prepare_features(df)
            X_scaled = self.scaler.transform(X[-1:])
            
            # Predict
            prediction = self.model.predict(X_scaled)[0]
            probabilities = self.model.predict_proba(X_scaled)[0]
            confidence = np.max(probabilities)
            
            return int(prediction), float(confidence)
            
        except Exception as e:
            self.logger.exception(f"Error in prediction: {e}")
            return 0, 0.0
    
    def save(self, path: Optional[str] = None):
        """Save model to disk."""
        if path is None:
            path = self.config.MODEL_SAVE_PATH / "random_forest_model.joblib"
        
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'is_trained': self.is_trained
        }, path)
        
        self.logger.info(f"Model saved to {path}")
    
    def load(self, path: Optional[str] = None):
        """Load model from disk."""
        if path is None:
            path = self.config.MODEL_SAVE_PATH / "random_forest_model.joblib"
        
        if not Path(path).exists():
            self.logger.warning(f"Model file not found: {path}")
            return
        
        data = joblib.load(path)
        self.model = data['model']
        self.scaler = data['scaler']
        self.feature_names = data['feature_names']
        self.is_trained = data['is_trained']
        
        self.logger.info(f"Model loaded from {path}")
    
    # Technical indicator calculation methods
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """Calculate RSI."""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calculate_macd(
        self, 
        prices: pd.Series,
        fast: int = 12,
        slow: int = 26,
        signal: int = 9
    ) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """Calculate MACD."""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        signal_line = macd.ewm(span=signal).mean()
        histogram = macd - signal_line
        return macd, signal_line, histogram
    
    def _calculate_bollinger_bands(
        self,
        prices: pd.Series,
        period: int = 20,
        std_dev: float = 2
    ) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """Calculate Bollinger Bands."""
        middle = prices.rolling(window=period).mean()
        std = prices.rolling(window=period).std()
        upper = middle + (std * std_dev)
        lower = middle - (std * std_dev)
        return upper, middle, lower
    
    def _calculate_stochastic(
        self,
        df: pd.DataFrame,
        period: int = 14
    ) -> Tuple[pd.Series, pd.Series]:
        """Calculate Stochastic Oscillator."""
        low_min = df['low'].rolling(window=period).min()
        high_max = df['high'].rolling(window=period).max()
        k = 100 * (df['close'] - low_min) / (high_max - low_min)
        d = k.rolling(window=3).mean()
        return k, d
    
    def _calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range."""
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df['close'].shift())
        low_close = np.abs(df['low'] - df['close'].shift())
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = np.max(ranges, axis=1)
        atr = pd.Series(true_range).rolling(period).mean()
        return atr
    
    def _calculate_adx(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average Directional Index."""
        high_diff = df['high'].diff()
        low_diff = -df['low'].diff()
        
        pos_dm = high_diff.where((high_diff > low_diff) & (high_diff > 0), 0)
        neg_dm = low_diff.where((low_diff > high_diff) & (low_diff > 0), 0)
        
        atr = self._calculate_atr(df, period)
        
        pos_di = 100 * (pos_dm.rolling(period).mean() / atr)
        neg_di = 100 * (neg_dm.rolling(period).mean() / atr)
        
        dx = 100 * np.abs(pos_di - neg_di) / (pos_di + neg_di)
        adx = dx.rolling(period).mean()
        
        return adx


if __name__ == "__main__":
    # Test Random Forest model
    from config.settings import settings
    
    print("Testing Random Forest Model...")
    
    # Create sample data
    dates = pd.date_range('2023-01-01', periods=1000, freq='1H')
    df = pd.DataFrame({
        'open': np.random.uniform(100, 110, 1000),
        'high': np.random.uniform(110, 115, 1000),
        'low': np.random.uniform(95, 100, 1000),
        'close': np.random.uniform(100, 110, 1000),
        'volume': np.random.uniform(1000, 2000, 1000)
    }, index=dates)
    
    # Create sample labels
    labels = np.random.choice([-1, 0, 1], size=1000)
    
    # Initialize and train
    model = RandomForestModel(settings)
    metrics = model.train(df, labels)
    
    print(f"\nTraining Metrics:")
    print(f"  Accuracy: {metrics.get('accuracy', 0):.4f}")
    print(f"  Samples: {metrics.get('n_samples', 0)}")
    print(f"  Features: {metrics.get('n_features', 0)}")
    
    # Test prediction
    prediction, confidence = model.predict(df)
    print(f"\nPrediction: {prediction}, Confidence: {confidence:.4f}")
    
    print("\nRandom Forest Model test completed!")