"""
LSTM Model - Model 3
Author: BLESSING OMOREGIE
GitHub: Nixiestone
Repository: nyx_trial

DO NOT EDIT THIS FILE
LSTM Neural Network for time series price prediction.
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from pathlib import Path
from typing import Optional, Tuple

try:
    import tensorflow as tf
    from tensorflow import keras
    layers = keras.layers
    
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False

from ..utils.logger import get_logger


class LSTMModel:
    """
    LSTM model for predicting price direction using time series.
    Predicts: -1 (sell), 0 (neutral), 1 (buy)
    """
    
    def __init__(self, config, sequence_length: int = 60):
        """
        Initialize LSTM model.
        
        Args:
            config: Settings object
            sequence_length: Number of time steps to use
        """
        self.config = config
        self.logger = get_logger(__name__, config.LOG_LEVEL, config.LOG_FILE_PATH)
        self.sequence_length = sequence_length
        
        if not TENSORFLOW_AVAILABLE:
            self.logger.warning("TensorFlow not available. LSTM model disabled.")
            self.model = None
            self.is_trained = False
            return
        
        self.scaler = MinMaxScaler()
        self.is_trained = False
        self.model = None
    
    def _build_model(self, input_shape: tuple) -> keras.Model:
        """
        Build LSTM neural network architecture.
        
        Args:
            input_shape: Shape of input data
            
        Returns:
            Compiled Keras model
        """
        model = keras.Sequential([
            # First LSTM layer
            layers.LSTM(
                64,
                return_sequences=True,
                input_shape=input_shape
            ),
            layers.Dropout(0.2),
            
            # Second LSTM layer
            layers.LSTM(32, return_sequences=False),
            layers.Dropout(0.2),
            
            # Dense layers
            layers.Dense(16, activation='relu'),
            layers.Dropout(0.1),
            
            # Output layer (3 classes: -1, 0, 1)
            layers.Dense(3, activation='softmax')
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def prepare_sequences(
        self,
        df: pd.DataFrame
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Prepare sequences for LSTM training.
        
        Args:
            df: DataFrame with OHLCV data
            
        Returns:
            Tuple of (X sequences, feature names)
        """
        # Select features
        feature_cols = ['open', 'high', 'low', 'close', 'volume']
        
        # Add technical indicators
        df_features = df[feature_cols].copy()
        
        # Returns
        df_features['returns'] = df['close'].pct_change()
        
        # Moving averages
        df_features['sma_10'] = df['close'].rolling(10).mean()
        df_features['sma_20'] = df['close'].rolling(20).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss
        df_features['rsi'] = 100 - (100 / (1 + rs))
        
        # Fill NaN
        df_features = df_features.fillna(method='bfill').fillna(0)
        
        # Scale data
        scaled_data = self.scaler.fit_transform(df_features)
        
        # Create sequences
        X = []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i-self.sequence_length:i])
        
        return np.array(X), df_features.columns.tolist()
    
    def train(
        self,
        df: pd.DataFrame,
        labels: np.ndarray,
        epochs: int = 50,
        batch_size: int = 32
    ) -> dict:
        """
        Train the LSTM model.
        
        Args:
            df: DataFrame with OHLCV data
            labels: Array of labels (-1, 0, 1)
            epochs: Number of training epochs
            batch_size: Batch size for training
            
        Returns:
            Dictionary with training metrics
        """
        if not TENSORFLOW_AVAILABLE:
            self.logger.error("TensorFlow not available")
            return {'model': 'lstm', 'error': 'TensorFlow not installed'}
        
        try:
            self.logger.info("Training LSTM model...")
            
            # Prepare sequences
            X, feature_names = self.prepare_sequences(df)
            
            # Align labels with sequences
            y = labels[self.sequence_length:]
            
            # Remove NaN labels
            valid_idx = ~np.isnan(y)
            X = X[valid_idx]
            y = y[valid_idx]
            
            # Remap labels to 0, 1, 2
            y_mapped = y + 1
            
            # Build model
            if self.model is None:
                self.model = self._build_model((X.shape[1], X.shape[2]))
            
            # Train model
            history = self.model.fit(
                X, y_mapped,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=0.2,
                verbose=0
            )
            
            # Get final accuracy
            final_accuracy = history.history['accuracy'][-1]
            val_accuracy = history.history['val_accuracy'][-1]
            
            self.is_trained = True
            
            self.logger.info(
                f"LSTM trained. "
                f"Train Accuracy: {final_accuracy:.4f}, "
                f"Val Accuracy: {val_accuracy:.4f}"
            )
            
            return {
                'model': 'lstm',
                'train_accuracy': final_accuracy,
                'val_accuracy': val_accuracy,
                'n_samples': len(y),
                'sequence_length': self.sequence_length,
                'n_features': X.shape[2],
                'epochs': epochs
            }
            
        except Exception as e:
            self.logger.exception(f"Error training LSTM: {e}")
            return {'model': 'lstm', 'error': str(e)}
    
    def predict(self, df: pd.DataFrame) -> Tuple[int, float]:
        """
        Predict price direction.
        
        Args:
            df: DataFrame with OHLCV data
            
        Returns:
            Tuple of (prediction, confidence)
        """
        if not TENSORFLOW_AVAILABLE or not self.is_trained:
            self.logger.warning("LSTM not available or not trained")
            return 0, 0.33
        
        try:
            # Prepare sequence
            X, _ = self.prepare_sequences(df)
            
            if len(X) == 0:
                return 0, 0.33
            
            # Take last sequence
            X_last = X[-1:]
            
            # Predict
            probabilities = self.model.predict(X_last, verbose=0)[0]
            prediction_mapped = np.argmax(probabilities)
            prediction = int(prediction_mapped) - 1  # Remap to -1, 0, 1
            confidence = float(np.max(probabilities))
            
            return prediction, confidence
            
        except Exception as e:
            self.logger.exception(f"Error in LSTM prediction: {e}")
            return 0, 0.0
    
    def save(self, path: Optional[str] = None):
        """Save model to disk."""
        if not TENSORFLOW_AVAILABLE or self.model is None:
            return
        
        if path is None:
            path = self.config.MODEL_SAVE_PATH / "lstm_model.h5"
        
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        self.model.save(path)
        
        # Save scaler separately
        import joblib
        scaler_path = Path(path).parent / "lstm_scaler.joblib"
        joblib.dump(self.scaler, scaler_path)
        
        self.logger.info(f"LSTM model saved to {path}")
    
    def load(self, path: Optional[str] = None):
        """Load model from disk."""
        if not TENSORFLOW_AVAILABLE:
            return
        
        if path is None:
            path = self.config.MODEL_SAVE_PATH / "lstm_model.h5"
        
        if not Path(path).exists():
            self.logger.warning(f"Model file not found: {path}")
            return
        
        self.model = keras.models.load_model(path)
        
        # Load scaler
        import joblib
        scaler_path = Path(path).parent / "lstm_scaler.joblib"
        if scaler_path.exists():
            self.scaler = joblib.load(scaler_path)
        
        self.is_trained = True
        self.logger.info(f"LSTM model loaded from {path}")


if __name__ == "__main__":
    # Test LSTM model
    from config.settings import settings
    
    print("Testing LSTM Model...")
    
    if not TENSORFLOW_AVAILABLE:
        print("TensorFlow not installed. Install with: pip install tensorflow")
    else:
        # Create sample data
        dates = pd.date_range('2023-01-01', periods=1000, freq='1H')
        df = pd.DataFrame({
            'open': np.random.uniform(100, 110, 1000),
            'high': np.random.uniform(110, 115, 1000),
            'low': np.random.uniform(95, 100, 1000),
            'close': np.random.uniform(100, 110, 1000),
            'volume': np.random.uniform(1000, 2000, 1000)
        }, index=dates)
        
        # Create sample labels
        labels = np.random.choice([-1, 0, 1], size=1000)
        
        # Initialize and train
        model = LSTMModel(settings, sequence_length=60)
        metrics = model.train(df, labels, epochs=10)
        
        print(f"\nTraining Metrics:")
        print(f"  Train Accuracy: {metrics.get('train_accuracy', 0):.4f}")
        print(f"  Val Accuracy: {metrics.get('val_accuracy', 0):.4f}")
        print(f"  Samples: {metrics.get('n_samples', 0)}")
        
        # Test prediction
        prediction, confidence = model.predict(df)
        print(f"\nPrediction: {prediction}, Confidence: {confidence:.4f}")
    
    print("\nLSTM Model test completed!")